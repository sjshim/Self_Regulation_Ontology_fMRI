{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/sjshim/miniconda3/envs/fmri_analysis/lib/python3.9/site-packages/nilearn/glm/__init__.py:55: FutureWarning: The nilearn.glm module is experimental. It may change in any future release of Nilearn.\n",
      "  warn('The nilearn.glm module is experimental. '\n",
      "/home/users/sjshim/miniconda3/envs/fmri_analysis/lib/python3.9/site-packages/nilearn/datasets/__init__.py:86: FutureWarning: Fetchers from the nilearn.datasets module will be updated in version 0.9 to return python strings instead of bytes and Pandas dataframes instead of Numpy arrays.\n",
      "  warn(\"Fetchers from the nilearn.datasets module will be \"\n",
      "/home/groups/russpold/network_fmri/analysis/fmri_analysis/scripts/notebooks/utils/plot_utils.py:9: UserWarning: \n",
      "\n",
      " | Using Nistats with Nilearn versions >= 0.7.0 is redundant and potentially conflicting.\n",
      " | Nilearn versions 0.7.0 and up offer all the functionality of Nistats as well the latest features and fixes.\n",
      " | We strongly recommend uninstalling Nistats and using Nilearn's stats & reporting modules.\n",
      "\n",
      "  from nistats.reporting import plot_design_matrix, plot_contrast_matrix\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import argparse\n",
    "from inspect import currentframe, getframeinfo\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import os\n",
    "from os.path import join\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import sys\n",
    "import nibabel as nib\n",
    "from nilearn.glm.first_level import FirstLevelModel\n",
    "from nilearn.image import concat_imgs, resample_img, mean_img, smooth_img\n",
    "from nilearn.plotting import plot_epi, show\n",
    "import warnings\n",
    "from utils.plot_utils import plot_design\n",
    "from utils.firstlevel_utils import get_first_level_objs, make_first_level_obj, save_first_level_obj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse Arguments\n",
    "These are not needed for the jupyter notebook, but are used after conversion to a script for production\n",
    "\n",
    "- conversion command:\n",
    "  - jupyter nbconvert --to script --execute 1stlevel_analysis.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='First Level Entrypoint script')\n",
    "parser.add_argument('-data_dir', default='/data')\n",
    "parser.add_argument('-derivatives_dir', default=None)\n",
    "parser.add_argument('-fmriprep_dir', default=None)\n",
    "parser.add_argument('-working_dir', default=None)\n",
    "parser.add_argument('--subject_ids', nargs=\"+\")\n",
    "parser.add_argument('--tasks', nargs=\"+\", help=\"Choose from ANT, CCTHot, discountFix,                                     DPX, motorSelectiveStop, stopSignal,                                     stroop, surveyMedley, twoByTwo, WATT3\")\n",
    "parser.add_argument('--rt', action='store_true')\n",
    "parser.add_argument('--beta', action='store_true')\n",
    "parser.add_argument('--n_procs', default=16, type=int)\n",
    "parser.add_argument('--overwrite', action='store_true')\n",
    "parser.add_argument('--quiet', '-q', action='store_true')\n",
    "parser.add_argument('--design_matrix', '-dm', action='store_true')\n",
    "parser.add_argument('--a_comp_cor', action='store_true')\n",
    "\n",
    "if '-derivatives_dir' in sys.argv or '-h' in sys.argv:\n",
    "    args = parser.parse_args()\n",
    "else:\n",
    "    args = parser.parse_args([])\n",
    "#     args.tasks = ['discountFix', 'manipulationTask', #aim 2 tasks\n",
    "#                   'motorSelectiveStop', 'stopSignal']\n",
    "    \n",
    "    # args.tasks = ['ANT', 'CCTHot', 'discountFix', 'DPX', #aim 1 tasks\n",
    "    #               'motorSelectiveStop', 'stopSignal', \n",
    "    #               'stroop', 'twoByTwo', 'WATT3']\n",
    "    \n",
    "   \n",
    "    #args.subject_ids = ['3010']\n",
    "    args.rt=True\n",
    "    args.a_comp_cor=True\n",
    "    args.n_procs=1\n",
    "    args.derivatives_dir = '/oak/stanford/groups/russpold/data/network_grant/discovery_BIDS/derivatives'\n",
    "    args.data_dir = '/oak/stanford/groups/russpold/data/network_grant/discovery_BIDS'\n",
    "    args.fmriprep_dir = '/oak/stanford/groups/russpold/data/network_grant/discovery_BIDS/derivatives/SOBC_analysis'\n",
    "    args.design_matrix=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not args.quiet:\n",
    "    def verboseprint(*args, **kwargs):\n",
    "        print(*args, **kwargs)\n",
    "else:\n",
    "    verboseprint = lambda *a, **k: None # do-nothing function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Setup\n",
    "\n",
    "Organize paths and set parameters based on arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Paths\n",
    "derivatives_dir = args.derivatives_dir\n",
    "if args.fmriprep_dir is None:\n",
    "    fmriprep_dir = join(derivatives_dir, 'fmriprep')\n",
    "else:\n",
    "    fmriprep_dir = args.fmriprep_dir\n",
    "data_dir = args.data_dir\n",
    "first_level_dir = join(derivatives_dir,'1stlevel')\n",
    "if args.working_dir is None:\n",
    "    working_dir = join(derivatives_dir, '1stlevel_workingdir')\n",
    "else:\n",
    "    working_dir = join(args.working_dir, '1stlevel_workingdir')\n",
    "\n",
    "# set tasks\n",
    "if args.tasks is not None:\n",
    "    tasks = args.tasks\n",
    "else:\n",
    "    #tasks = ['flanker']\n",
    "    \n",
    "    tasks = ['cuedTS', 'directedForgetting', 'flanker', 'goNogo', \n",
    "                'nBack', 'shapeMatching', 'spatialTS',\n",
    "                'stopSignal', 'stopSignalWDirectedForgetting',\n",
    "                'stopSignalWFlanker', 'directedForgettingWFlanker']\n",
    "    \n",
    "    # tasks = ['ANT', 'CCTHot', 'discountFix', 'DPX', \n",
    "    #               'motorSelectiveStop', 'stopSignal', \n",
    "    #               'stroop', 'twoByTwo', 'WATT3']\n",
    "    \n",
    "\n",
    "# list of subject identifiers\n",
    "if not args.subject_ids:\n",
    "    subjects = sorted([i.split(\"-\")[-1] for i in glob(os.path.join(args.data_dir, '*')) if 'sub-' in i])\n",
    "else:\n",
    "    subjects = args.subject_ids\n",
    "ses = []\n",
    "for i in range(1, 10):\n",
    "    ses.append('ses-0'+str(i))\n",
    "for i in range(10, 13):\n",
    "    ses.append('ses-'+str(i))\n",
    "#removing pilot subject\n",
    "subjects.remove('n01')\n",
    "\n",
    "# other arguments\n",
    "regress_rt = args.rt\n",
    "beta_series = args.beta\n",
    "n_procs = args.n_procs\n",
    "# TR of functional images\n",
    "TR = 1.49\n",
    "a_comp_cor=args.a_comp_cor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/oak/stanford/groups/russpold/data/network_grant/discovery_BIDS/derivatives/1stlevel\n",
      "['s03', 's10', 's19', 's29', 's43']\n",
      "/oak/stanford/groups/russpold/data/network_grant/discovery_BIDS/derivatives/SOBC_analysis\n",
      "['ses-01', 'ses-02', 'ses-03', 'ses-04', 'ses-05', 'ses-06', 'ses-07', 'ses-08', 'ses-09', 'ses-10', 'ses-11', 'ses-12']\n"
     ]
    }
   ],
   "source": [
    "print(first_level_dir)\n",
    "print(subjects)\n",
    "print(fmriprep_dir)\n",
    "print(ses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************************************************************************\n",
      "Tasks: ['cuedTS', 'directedForgetting', 'flanker', 'goNogo', 'nBack', 'shapeMatching', 'spatialTS', 'stopSignal', 'stopSignalWDirectedForgetting', 'stopSignalWFlanker', 'directedForgettingWFlanker']\n",
      ", Subjects: ['s03', 's10', 's19', 's29', 's43']\n",
      ", derivatives_dir: /oak/stanford/groups/russpold/data/network_grant/discovery_BIDS/derivatives\n",
      ", data_dir: /oak/stanford/groups/russpold/data/network_grant/discovery_BIDS\n",
      "*******************************************************************************\n"
     ]
    }
   ],
   "source": [
    "verboseprint('*'*79)\n",
    "verboseprint('Tasks: %s\\n, Subjects: %s\\n, derivatives_dir: %s\\n, data_dir: %s' % \n",
    "     (tasks, subjects, derivatives_dir, data_dir))\n",
    "verboseprint('*'*79)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up Nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run analysis\n",
    "\n",
    "gather the files for each task within each subject\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s03 cuedTS\n",
      "['/oak/stanford/groups/russpold/data/network_grant/discovery_BIDS/derivatives/SOBC_analysis/sub-s03/ses-02/func/sub-s03_ses-02_task-cuedTS_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz', '/oak/stanford/groups/russpold/data/network_grant/discovery_BIDS/derivatives/SOBC_analysis/sub-s03/ses-04/func/sub-s03_ses-04_task-cuedTS_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz', '/oak/stanford/groups/russpold/data/network_grant/discovery_BIDS/derivatives/SOBC_analysis/sub-s03/ses-06/func/sub-s03_ses-06_task-cuedTS_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz', '/oak/stanford/groups/russpold/data/network_grant/discovery_BIDS/derivatives/SOBC_analysis/sub-s03/ses-08/func/sub-s03_ses-08_task-cuedTS_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz', '/oak/stanford/groups/russpold/data/network_grant/discovery_BIDS/derivatives/SOBC_analysis/sub-s03/ses-10/func/sub-s03_ses-10_task-cuedTS_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz']\n",
      "[[   2.     0.    -0.   -96.5]\n",
      " [   0.     2.    -0.  -132.5]\n",
      " [   0.     0.     2.   -78.5]\n",
      " [   0.     0.     0.     1. ]] (97, 115, 97, 334)\n",
      "(97, 115, 97, 334)\n",
      "(97, 115, 97)\n",
      "Resampling the second image (this takes time)...\n",
      "[<nibabel.nifti1.Nifti1Image object at 0x7f91da097f10>, <nibabel.nifti1.Nifti1Image object at 0x7f91da097f70>, <nibabel.nifti1.Nifti1Image object at 0x7f921065ca30>, <nibabel.nifti1.Nifti1Image object at 0x7f91da097d30>, <nibabel.nifti1.Nifti1Image object at 0x7f9210624190>]\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "s03 directedForgetting\n",
      "['/oak/stanford/groups/russpold/data/network_grant/discovery_BIDS/derivatives/SOBC_analysis/sub-s03/ses-02/func/sub-s03_ses-02_task-directedForgetting_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz', '/oak/stanford/groups/russpold/data/network_grant/discovery_BIDS/derivatives/SOBC_analysis/sub-s03/ses-04/func/sub-s03_ses-04_task-directedForgetting_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz', '/oak/stanford/groups/russpold/data/network_grant/discovery_BIDS/derivatives/SOBC_analysis/sub-s03/ses-06/func/sub-s03_ses-06_task-directedForgetting_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz', '/oak/stanford/groups/russpold/data/network_grant/discovery_BIDS/derivatives/SOBC_analysis/sub-s03/ses-08/func/sub-s03_ses-08_task-directedForgetting_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz', '/oak/stanford/groups/russpold/data/network_grant/discovery_BIDS/derivatives/SOBC_analysis/sub-s03/ses-10/func/sub-s03_ses-10_task-directedForgetting_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz', '/oak/stanford/groups/russpold/data/network_grant/discovery_BIDS/derivatives/SOBC_analysis/sub-s03/ses-11/func/sub-s03_ses-11_task-directedForgettingWFlanker_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz', '/oak/stanford/groups/russpold/data/network_grant/discovery_BIDS/derivatives/SOBC_analysis/sub-s03/ses-12/func/sub-s03_ses-12_task-directedForgettingWFlanker_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz']\n"
     ]
    }
   ],
   "source": [
    "for subject_id in subjects:\n",
    "    for task in tasks:\n",
    "        print(subject_id, task)\n",
    "        task_funcs = glob(fmriprep_dir+\"/sub-\"+subject_id+'/*/func/*' + task+ '*_bold.nii.gz')\n",
    "        task_funcs = sorted(task_funcs)\n",
    "        print(task_funcs)\n",
    "        fmri_img = []\n",
    "        for n in range(len(task_funcs)):\n",
    "            fmri_img.append(concat_imgs(task_funcs[n], auto_resample=True))\n",
    "        affine, shape = fmri_img[0].affine, fmri_img[0].shape\n",
    "        print(affine, shape)\n",
    "        print(shape)\n",
    "        print(shape[:3])\n",
    "        print('Resampling the second image (this takes time)...')\n",
    "        print(fmri_img)\n",
    "        for n in range(len(task_funcs)-1):\n",
    "            print(n+1)\n",
    "            #fmri_img[n+1] = resample_img(fmri_img[n+1], affine, shape[:3])\n",
    "        #mean_image = mean_img(fmri_img)\n",
    "        #plot_epi(mean_image)\n",
    "        #show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_run = []\n",
    "for subject_id in subjects:\n",
    "    for session in ses:\n",
    "        for task in tasks:\n",
    "            verboseprint('Setting up %s, %s' % (subject_id, task))\n",
    "            if task == 'goNogo':\n",
    "                event_files = glob(data_dir+\"/sub-\"+subject_id+'/'+session+'/func/*goNogo*events.tsv')\n",
    "                if len(event_files) != 0:\n",
    "                    event_df = pd.read_csv(event_files[0], sep='\\t')\n",
    "                    if event_df['trial_type'].str.contains('nogo_failure').any():\n",
    "                        task = 'goNogo_nogo_failure'\n",
    "                    else:\n",
    "                        task = 'goNogo'\n",
    "            files = get_first_level_objs(subject_id, session, task, first_level_dir, beta=False, regress_rt=regress_rt)\n",
    "            if len(files) == 0 or args.overwrite:\n",
    "                with warnings.catch_warnings():\n",
    "                    warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "                    warnings.filterwarnings(\"ignore\",category=UserWarning)\n",
    "                    subjinfo = make_first_level_obj(subject_id, session, task, fmriprep_dir, \n",
    "                                                    data_dir, first_level_dir, TR, regress_rt=regress_rt, a_comp_cor=a_comp_cor)\n",
    "                if subjinfo is not None:\n",
    "                    to_run.append(subjinfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run model fit\n",
    "\n",
    "generate the glm and fit the timeseries data to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subjinfo in to_run:\n",
    "    verboseprint(subjinfo.ID)\n",
    "    verboseprint('** fitting model')\n",
    "    fmri_glm = FirstLevelModel(TR, \n",
    "                           subject_label = subjinfo.ID,\n",
    "                           mask_img=subjinfo.mask,\n",
    "                           noise_model='ar1',\n",
    "                           standardize=False, \n",
    "                           hrf_model='spm',\n",
    "                           drift_model='cosine',\n",
    "                           n_jobs=1\n",
    "                          )\n",
    "    \n",
    "    if args.design_matrix:\n",
    "        verboseprint('** saving')\n",
    "        save_first_level_obj(subjinfo, first_level_dir, False)\n",
    "        subjinfo.export_design(first_level_dir)\n",
    "        subjinfo.export_events(first_level_dir)\n",
    "    else:\n",
    "        out = fmri_glm.fit(subjinfo.func, design_matrices=subjinfo.design)\n",
    "        subjinfo.fit_model = out\n",
    "\n",
    "        verboseprint('** saving')\n",
    "        save_first_level_obj(subjinfo, first_level_dir, True)\n",
    "        subjinfo.export_design(first_level_dir)\n",
    "        subjinfo.export_events(first_level_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "243px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
