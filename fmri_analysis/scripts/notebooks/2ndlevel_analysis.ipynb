{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/miniconda/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/usr/local/miniconda/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/usr/local/miniconda/lib/python3.7/site-packages/nipype/utils/misc.py:14: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Iterator\n",
      "/usr/local/miniconda/lib/python3.7/site-packages/nipype/utils/config.py:103: DeprecationWarning: This method will be removed in future versions.  Use 'parser.read_file()' instead.\n",
      "  self._config.readfp(StringIO(default_cfg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200729-22:03:41,584 duecredit ERROR:\n",
      "\t Failed to import duecredit due to No module named 'duecredit'\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "from glob import glob\n",
    "from os import makedirs, path\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "from nistats.second_level_model import SecondLevelModel\n",
    "from nistats.thresholding import map_threshold\n",
    "from nilearn import plotting\n",
    "from utils.firstlevel_utils import (get_first_level_objs, \n",
    "                                    get_first_level_maps, \n",
    "                                    load_first_level_objs, \n",
    "                                    FirstLevel)\n",
    "from utils.secondlevel_utils import create_group_mask, randomise\n",
    "from utils.utils import get_contrasts, get_flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from glob import glob\n",
    "# from nilearn import image\n",
    "# from nipype.caching import Memory\n",
    "from nipype.interfaces import fsl\n",
    "# import os \n",
    "# from os import path, remove\n",
    "# import shutil\n",
    "# from utils.utils import get_flags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse Arguments\n",
    "These are not needed for the jupyter notebook, but are used after conversion to a script for production\n",
    "\n",
    "- conversion command:\n",
    "  - jupyter nbconvert --to script --execute 2ndlevel_analysis.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='2nd level Entrypoint Script.')\n",
    "parser.add_argument('-derivatives_dir', default=None)\n",
    "parser.add_argument('--tasks', nargs=\"+\", help=\"Choose from ANT, CCTHot, discountFix, \\\n",
    "                                    DPX, motorSelectiveStop, stopSignal, \\\n",
    "                                    stroop, surveyMedley, twoByTwo, WATT3\")\n",
    "parser.add_argument('--rerun', action='store_true')\n",
    "parser.add_argument('--rt', action='store_true')\n",
    "parser.add_argument('--beta', action='store_true')\n",
    "parser.add_argument('--n_perms', default=1000, type=int)\n",
    "parser.add_argument('--quiet', '-q', action='store_true')\n",
    "\n",
    "if '-derivatives_dir' in sys.argv or '-h' in sys.argv:\n",
    "    args = parser.parse_args()\n",
    "else:\n",
    "    args = parser.parse_args([])\n",
    "    args.derivatives_dir = '/data/derivatives/'\n",
    "    args.tasks = ['stroop']\n",
    "    args.rt=True\n",
    "    args.n_perms = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not args.quiet:\n",
    "    def verboseprint(*args, **kwargs):\n",
    "        print(*args, **kwargs)\n",
    "else:\n",
    "    verboseprint = lambda *a, **k: None # do-nothing function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "Organize paths and set parameters based on arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34ms061\u001b[0m/  \u001b[01;34ms465\u001b[0m/  \u001b[01;34ms524\u001b[0m/  \u001b[01;34ms555\u001b[0m/  \u001b[01;34ms574\u001b[0m/  \u001b[01;34ms588\u001b[0m/  \u001b[01;34ms598\u001b[0m/  \u001b[01;34ms611\u001b[0m/  \u001b[01;34ms622\u001b[0m/  \u001b[01;34ms635\u001b[0m/  \u001b[01;34ms645\u001b[0m/\n",
      "\u001b[01;34ms130\u001b[0m/  \u001b[01;34ms471\u001b[0m/  \u001b[01;34ms525\u001b[0m/  \u001b[01;34ms556\u001b[0m/  \u001b[01;34ms577\u001b[0m/  \u001b[01;34ms589\u001b[0m/  \u001b[01;34ms601\u001b[0m/  \u001b[01;34ms612\u001b[0m/  \u001b[01;34ms623\u001b[0m/  \u001b[01;34ms636\u001b[0m/  \u001b[01;34ms646\u001b[0m/\n",
      "\u001b[01;34ms144\u001b[0m/  \u001b[01;34ms483\u001b[0m/  \u001b[01;34ms526\u001b[0m/  \u001b[01;34ms557\u001b[0m/  \u001b[01;34ms579\u001b[0m/  \u001b[01;34ms590\u001b[0m/  \u001b[01;34ms602\u001b[0m/  \u001b[01;34ms613\u001b[0m/  \u001b[01;34ms624\u001b[0m/  \u001b[01;34ms637\u001b[0m/  \u001b[01;34ms647\u001b[0m/\n",
      "\u001b[01;34ms172\u001b[0m/  \u001b[01;34ms491\u001b[0m/  \u001b[01;34ms533\u001b[0m/  \u001b[01;34ms558\u001b[0m/  \u001b[01;34ms581\u001b[0m/  \u001b[01;34ms591\u001b[0m/  \u001b[01;34ms603\u001b[0m/  \u001b[01;34ms614\u001b[0m/  \u001b[01;34ms626\u001b[0m/  \u001b[01;34ms638\u001b[0m/  \u001b[01;34ms648\u001b[0m/\n",
      "\u001b[01;34ms192\u001b[0m/  \u001b[01;34ms495\u001b[0m/  \u001b[01;34ms541\u001b[0m/  \u001b[01;34ms561\u001b[0m/  \u001b[01;34ms582\u001b[0m/  \u001b[01;34ms592\u001b[0m/  \u001b[01;34ms605\u001b[0m/  \u001b[01;34ms615\u001b[0m/  \u001b[01;34ms627\u001b[0m/  \u001b[01;34ms639\u001b[0m/  \u001b[01;34ms649\u001b[0m/\n",
      "\u001b[01;34ms234\u001b[0m/  \u001b[01;34ms497\u001b[0m/  \u001b[01;34ms546\u001b[0m/  \u001b[01;34ms567\u001b[0m/  \u001b[01;34ms583\u001b[0m/  \u001b[01;34ms593\u001b[0m/  \u001b[01;34ms606\u001b[0m/  \u001b[01;34ms616\u001b[0m/  \u001b[01;34ms628\u001b[0m/  \u001b[01;34ms640\u001b[0m/  \u001b[01;34ms650\u001b[0m/\n",
      "\u001b[01;34ms251\u001b[0m/  \u001b[01;34ms499\u001b[0m/  \u001b[01;34ms548\u001b[0m/  \u001b[01;34ms568\u001b[0m/  \u001b[01;34ms584\u001b[0m/  \u001b[01;34ms594\u001b[0m/  \u001b[01;34ms607\u001b[0m/  \u001b[01;34ms617\u001b[0m/  \u001b[01;34ms629\u001b[0m/  \u001b[01;34ms641\u001b[0m/\n",
      "\u001b[01;34ms358\u001b[0m/  \u001b[01;34ms512\u001b[0m/  \u001b[01;34ms549\u001b[0m/  \u001b[01;34ms570\u001b[0m/  \u001b[01;34ms585\u001b[0m/  \u001b[01;34ms595\u001b[0m/  \u001b[01;34ms608\u001b[0m/  \u001b[01;34ms618\u001b[0m/  \u001b[01;34ms631\u001b[0m/  \u001b[01;34ms642\u001b[0m/\n",
      "\u001b[01;34ms373\u001b[0m/  \u001b[01;34ms518\u001b[0m/  \u001b[01;34ms553\u001b[0m/  \u001b[01;34ms572\u001b[0m/  \u001b[01;34ms586\u001b[0m/  \u001b[01;34ms596\u001b[0m/  \u001b[01;34ms609\u001b[0m/  \u001b[01;34ms619\u001b[0m/  \u001b[01;34ms633\u001b[0m/  \u001b[01;34ms643\u001b[0m/\n",
      "\u001b[01;34ms445\u001b[0m/  \u001b[01;34ms519\u001b[0m/  \u001b[01;34ms554\u001b[0m/  \u001b[01;34ms573\u001b[0m/  \u001b[01;34ms587\u001b[0m/  \u001b[01;34ms597\u001b[0m/  \u001b[01;34ms610\u001b[0m/  \u001b[01;34ms621\u001b[0m/  \u001b[01;34ms634\u001b[0m/  \u001b[01;34ms644\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "ls /data/derivatives/1stlevel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set paths\n",
    "first_level_dir = path.join(args.derivatives_dir, '1stlevel')\n",
    "second_level_dir = path.join(args.derivatives_dir,'2ndlevel')\n",
    "fmriprep_dir = path.join(args.derivatives_dir, 'fmriprep')\n",
    "\n",
    "# set tasks\n",
    "if args.tasks is not None:\n",
    "    tasks = args.tasks\n",
    "else:\n",
    "    tasks = ['ANT', 'CCTHot', 'discountFix',\n",
    "            'DPX', 'motorSelectiveStop',\n",
    "            'stopSignal', 'stroop',\n",
    "            'twoByTwo', 'WATT3']\n",
    "    \n",
    "# set other variables\n",
    "regress_rt = args.rt\n",
    "beta_series = args.beta\n",
    "n_perms = args.n_perms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_threshold = .95\n",
    "mask_loc = path.join(second_level_dir, 'group_mask_thresh-%s.nii.gz' % str(mask_threshold))\n",
    "if path.exists(mask_loc) == False or args.rerun:\n",
    "    verboseprint('Making group mask')\n",
    "    group_mask = create_group_mask(fmriprep_dir, mask_threshold)\n",
    "    makedirs(path.dirname(mask_loc), exist_ok=True)\n",
    "    group_mask.to_filename(mask_loc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create second level objects\n",
    "Gather first level models and create second level model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "aim1_2ndlevel_confounds_path = '../aim1_2ndlevel_regressors/aim1_2ndlevel_confounds_matrix.csv'\n",
    "full_confounds_df = pd.read_csv(aim1_2ndlevel_confounds_path, index_col='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>ANT_meanFD</th>\n",
       "      <th>CCTHot_meanFD</th>\n",
       "      <th>DPX_meanFD</th>\n",
       "      <th>WATT3_meanFD</th>\n",
       "      <th>discountFix_meanFD</th>\n",
       "      <th>motorSelectiveStop_meanFD</th>\n",
       "      <th>rest_meanFD</th>\n",
       "      <th>stopSignal_meanFD</th>\n",
       "      <th>stroop_meanFD</th>\n",
       "      <th>surveyMedley_meanFD</th>\n",
       "      <th>twoByTwo_meanFD</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>s061</th>\n",
       "      <td>41.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.137224</td>\n",
       "      <td>0.108978</td>\n",
       "      <td>0.151611</td>\n",
       "      <td>0.134908</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.119460</td>\n",
       "      <td>0.125783</td>\n",
       "      <td>0.104488</td>\n",
       "      <td>0.138526</td>\n",
       "      <td>0.124104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s130</th>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041484</td>\n",
       "      <td>0.031070</td>\n",
       "      <td>0.044276</td>\n",
       "      <td>0.045655</td>\n",
       "      <td>0.036948</td>\n",
       "      <td>0.036940</td>\n",
       "      <td>0.039885</td>\n",
       "      <td>0.031040</td>\n",
       "      <td>0.038328</td>\n",
       "      <td>0.030956</td>\n",
       "      <td>0.038415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s144</th>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.066086</td>\n",
       "      <td>0.074673</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.077678</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.057375</td>\n",
       "      <td>0.056909</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.062426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s172</th>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.050340</td>\n",
       "      <td>0.055910</td>\n",
       "      <td>0.068629</td>\n",
       "      <td>0.061671</td>\n",
       "      <td>0.065435</td>\n",
       "      <td>0.067503</td>\n",
       "      <td>0.050112</td>\n",
       "      <td>0.056833</td>\n",
       "      <td>0.063870</td>\n",
       "      <td>0.068802</td>\n",
       "      <td>0.054902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s192</th>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.094071</td>\n",
       "      <td>0.097725</td>\n",
       "      <td>0.066249</td>\n",
       "      <td>0.092005</td>\n",
       "      <td>0.069987</td>\n",
       "      <td>0.072108</td>\n",
       "      <td>0.086492</td>\n",
       "      <td>0.088668</td>\n",
       "      <td>0.067839</td>\n",
       "      <td>0.070347</td>\n",
       "      <td>0.100996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s646</th>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.061674</td>\n",
       "      <td>0.068604</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.065120</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.060531</td>\n",
       "      <td>0.070464</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.074248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s647</th>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.100468</td>\n",
       "      <td>0.090287</td>\n",
       "      <td>0.068654</td>\n",
       "      <td>0.081480</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.068188</td>\n",
       "      <td>0.061891</td>\n",
       "      <td>0.087776</td>\n",
       "      <td>0.060760</td>\n",
       "      <td>0.074409</td>\n",
       "      <td>0.090747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s648</th>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.061739</td>\n",
       "      <td>0.063606</td>\n",
       "      <td>0.063945</td>\n",
       "      <td>0.063606</td>\n",
       "      <td>0.074744</td>\n",
       "      <td>0.060855</td>\n",
       "      <td>0.059342</td>\n",
       "      <td>0.054841</td>\n",
       "      <td>0.053409</td>\n",
       "      <td>0.044231</td>\n",
       "      <td>0.061739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s649</th>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.158758</td>\n",
       "      <td>0.158758</td>\n",
       "      <td>0.202281</td>\n",
       "      <td>0.227551</td>\n",
       "      <td>0.112317</td>\n",
       "      <td>0.148466</td>\n",
       "      <td>0.142411</td>\n",
       "      <td>0.158758</td>\n",
       "      <td>0.112317</td>\n",
       "      <td>0.135755</td>\n",
       "      <td>0.227551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s650</th>\n",
       "      <td>45.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.200641</td>\n",
       "      <td>0.250026</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.274118</td>\n",
       "      <td>0.250764</td>\n",
       "      <td>0.253770</td>\n",
       "      <td>0.149828</td>\n",
       "      <td>0.231252</td>\n",
       "      <td>0.189059</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  sex  ANT_meanFD  CCTHot_meanFD  DPX_meanFD  WATT3_meanFD  \\\n",
       "index                                                                   \n",
       "s061   41.0  1.0         NaN       0.137224    0.108978      0.151611   \n",
       "s130   27.0  0.0    0.041484       0.031070    0.044276      0.045655   \n",
       "s144   19.0  0.0    0.066086       0.074673         NaN      0.077678   \n",
       "s172   19.0  0.0    0.050340       0.055910    0.068629      0.061671   \n",
       "s192   18.0  0.0    0.094071       0.097725    0.066249      0.092005   \n",
       "...     ...  ...         ...            ...         ...           ...   \n",
       "s646   22.0  1.0    0.061674       0.068604         NaN      0.065120   \n",
       "s647   24.0  0.0    0.100468       0.090287    0.068654      0.081480   \n",
       "s648   30.0  0.0    0.061739       0.063606    0.063945      0.063606   \n",
       "s649   22.0  0.0    0.158758       0.158758    0.202281      0.227551   \n",
       "s650   45.0  1.0         NaN       0.200641    0.250026           NaN   \n",
       "\n",
       "       discountFix_meanFD  motorSelectiveStop_meanFD  rest_meanFD  \\\n",
       "index                                                               \n",
       "s061             0.134908                        NaN     0.119460   \n",
       "s130             0.036948                   0.036940     0.039885   \n",
       "s144                  NaN                        NaN     0.057375   \n",
       "s172             0.065435                   0.067503     0.050112   \n",
       "s192             0.069987                   0.072108     0.086492   \n",
       "...                   ...                        ...          ...   \n",
       "s646                  NaN                        NaN     0.060531   \n",
       "s647                  NaN                   0.068188     0.061891   \n",
       "s648             0.074744                   0.060855     0.059342   \n",
       "s649             0.112317                   0.148466     0.142411   \n",
       "s650             0.274118                   0.250764     0.253770   \n",
       "\n",
       "       stopSignal_meanFD  stroop_meanFD  surveyMedley_meanFD  twoByTwo_meanFD  \n",
       "index                                                                          \n",
       "s061            0.125783       0.104488             0.138526         0.124104  \n",
       "s130            0.031040       0.038328             0.030956         0.038415  \n",
       "s144            0.056909            NaN                  NaN         0.062426  \n",
       "s172            0.056833       0.063870             0.068802         0.054902  \n",
       "s192            0.088668       0.067839             0.070347         0.100996  \n",
       "...                  ...            ...                  ...              ...  \n",
       "s646            0.070464            NaN                  NaN         0.074248  \n",
       "s647            0.087776       0.060760             0.074409         0.090747  \n",
       "s648            0.054841       0.053409             0.044231         0.061739  \n",
       "s649            0.158758       0.112317             0.135755         0.227551  \n",
       "s650            0.149828       0.231252             0.189059              NaN  \n",
       "\n",
       "[108 rows x 13 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_confounds_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contrast-RT.nii.gz  contrast-congruency.nii.gz  contrast-task.nii.gz\n"
     ]
    }
   ],
   "source": [
    "ls /data/derivatives/1stlevel/s061/stroop/maps_RT-True_beta-False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up 2ndlevel Regressors - Added by HMJ 7.29.20\n",
    "aim1_2ndlevel_confounds_path = '../aim1_2ndlevel_regressors/aim1_2ndlevel_confounds_matrix.csv'\n",
    "full_confounds_df = pd.read_csv(aim1_2ndlevel_confounds_path, index_col='index')\n",
    "\n",
    "def get_2ndlevel_designMatrix_andContrasts(maps, task):\n",
    "    design_matrix = pd.DataFrame([1] * len(maps), columns=['intercept'])\n",
    "    contrasts = [1]\n",
    "    if 'aim1'=='aim1':\n",
    "        subjects = [m.split('1stlevel/')[-1].split('/')[0] for m in maps]\n",
    "        design_matrix = full_confounds_df.loc[subjects, ['age', 'sex', task+'_meanFD']].copy()\n",
    "        design_matrix.index.rename('subject_label', inplace=True)\n",
    "        design_matrix['intercept'] = 1\n",
    "        contrasts = [0, 0, 0, 1]\n",
    "    return design_matrix, contrasts\n",
    "\n",
    "def filter_maps_designMatrix(maps, design_matrix):\n",
    "    design_matrix = design_matrix.dropna()\n",
    "    if len(design_matrix)!=len(maps):\n",
    "        keep_subs = dm.index.tolist()\n",
    "        maps = [m for m in maps if m.split('1stlevel/')[-1].split('/')[0] in keep_subs]\n",
    "    assert(len(design_matrix)==len(maps))\n",
    "    return maps, design_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 2nd level for stroop\n",
      "*** Creating maps\n",
      "****** congruency, 100 files found\n"
     ]
    }
   ],
   "source": [
    "rt_flag, beta_flag = get_flags(regress_rt, beta_series)\n",
    "for task in tasks:\n",
    "    verboseprint('Running 2nd level for %s' % task)\n",
    "    # load first level models\n",
    "    # create contrast maps\n",
    "    verboseprint('*** Creating maps')\n",
    "    task_contrasts = get_contrasts(task, regress_rt)\n",
    "    maps_dir = path.join(second_level_dir, task, 'secondlevel-%s_%s_maps' % (rt_flag, beta_flag))\n",
    "    makedirs(maps_dir, exist_ok=True)\n",
    "    # run through each contrast\n",
    "    for name, contrast in [task_contrasts[0]]:\n",
    "        second_level_model = SecondLevelModel(mask=mask_loc, smoothing_fwhm=6)\n",
    "        maps = get_first_level_maps('*', task, first_level_dir, name, regress_rt, beta_series)\n",
    "        N = str(len(maps)).zfill(2)\n",
    "        verboseprint('****** %s, %s files found' % (name, N))\n",
    "        if len(maps) <= 1:\n",
    "            verboseprint('****** No Maps')\n",
    "            continue\n",
    "        design_matrix, curr_contrasts = get_2ndlevel_designMatrix_andContrasts(maps, task)\n",
    "        maps, design_matrix = filter_maps_designMatrix(maps, design_matrix)\n",
    "        second_level_model.fit(maps, design_matrix=design_matrix)\n",
    "        contrast_map = second_level_model.compute_contrast(second_level_contrast=curr_contrasts)\n",
    "#         # save\n",
    "#         contrast_file = path.join(maps_dir, 'contrast-%s.nii.gz' % name)\n",
    "#         contrast_map.to_filename(contrast_file)\n",
    "#          # write metadata\n",
    "#         with open(path.join(maps_dir, 'metadata.txt'), 'a') as f:\n",
    "#             f.write('Contrast-%s: %s maps\\n' % (contrast, N))\n",
    "#         # save corrected map\n",
    "#         if n_perms > 0:\n",
    "#             verboseprint('*** Running Randomise')\n",
    "#             randomise(maps, maps_dir, mask_loc, n_perms=n_perms)\n",
    "#             # write metadata\n",
    "#             with open(path.join(maps_dir, 'metadata.txt'), 'a') as f:\n",
    "#                 f.write('Contrast-%s: Randomise run with %s permutations\\n' % (contrast, str(n_perms)))\n",
    "#     verboseprint('Done with %s' % task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nilearn.plotting as plotting\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_img(contrast_map)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Using nistats method of first level objects. Not conducive for randomise.\n",
    "rt_flag, beta_flag = get_flags(regress_rt, beta_series)\n",
    "for task in tasks:\n",
    "    verboseprint('Running 2nd level for %s' % task)\n",
    "    # load first level models\n",
    "    first_levels = load_first_level_objs(task, first_level_dir, regress_rt=regress_rt)\n",
    "    if len(first_levels) == 0:\n",
    "        continue\n",
    "    first_level_models = [subj.fit_model for subj in first_levels]\n",
    "    N = str(len(first_level_models)).zfill(2)\n",
    "\n",
    "    # simple design for one sample test\n",
    "    design_matrix = pd.DataFrame([1] * len(first_level_models), columns=['intercept'])\n",
    "    \n",
    "    # run second level\n",
    "    verboseprint('*** Running model. %s first level files found' % N)\n",
    "    second_level_model = SecondLevelModel(mask=mask_loc, smoothing_fwhm=6).fit(\n",
    "        first_level_models, design_matrix=design_matrix)\n",
    "    makedirs(path.join(second_level_dir, task), exist_ok=True)\n",
    "    f = open(path.join(second_level_dir, task, 'secondlevel_%s_%s.pkl' % (rt_flag, beta_flag)), 'wb')\n",
    "    pickle.dump(second_level_model, f)\n",
    "    f.close()\n",
    "    \n",
    "    # create contrast maps\n",
    "    verboseprint('*** Creating maps')\n",
    "    task_contrasts = get_contrasts(task, regress_rt)\n",
    "    maps_dir = path.join(second_level_dir, task, 'secondlevel_%s_%s_N-%s_maps' % (rt_flag, beta_flag, N))\n",
    "    makedirs(maps_dir, exist_ok=True)\n",
    "    for name, contrast in task_contrasts:\n",
    "        verboseprint('****** %s' % name)\n",
    "        contrast_map = second_level_model.compute_contrast(first_level_contrast=contrast)\n",
    "        contrast_file = path.join(maps_dir, 'contrast-%s.nii.gz' % name)\n",
    "        contrast_map.to_filename(contrast_file)\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
