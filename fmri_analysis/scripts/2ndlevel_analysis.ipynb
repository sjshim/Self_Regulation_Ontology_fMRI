{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from functools import partial\n",
    "from glob import glob\n",
    "from itertools import combinations\n",
    "from joblib import Parallel, delayed\n",
    "import json\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n",
    "import nibabel\n",
    "import nilearn\n",
    "from nilearn import datasets, image\n",
    "import numpy as np\n",
    "from os import makedirs, path, sep\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import shutil\n",
    "import sys\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from scipy.spatial.distance import squareform\n",
    "\n",
    "from utils.secondlevel_utils import *\n",
    "from utils.secondlevel_plot_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports for plotting exploring\n",
    "import matplotlib\n",
    "matplotlib.use(\"agg\")\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from nilearn import plotting\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse Arguments\n",
    "These are not needed for the jupyter notebook, but are used after conversion to a script for production\n",
    "\n",
    "- conversion command:\n",
    "  - jupyter nbconvert --to script --execute 2ndlevel_analysis.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='fMRI Analysis Entrypoint Script.')\n",
    "parser.add_argument('-derivatives_dir')\n",
    "parser.add_argument('-working_dir', default=None)\n",
    "parser.add_argument('--tasks', nargs=\"+\")\n",
    "parser.add_argument('--n_procs', default=4, type=int)\n",
    "parser.add_argument('--num_perm', default=1000, type=int, help=\"Passed to fsl.randomize\")\n",
    "parser.add_argument('--ignore_rt', action='store_false')\n",
    "parser.add_argument('--rerun', action='store_true')\n",
    "parser.add_argument('--mask_threshold', default=.8, type=float)\n",
    "if '-derivatives_dir' in sys.argv or '-h' in sys.argv:\n",
    "    matplotlib.use(\"agg\")\n",
    "    args = parser.parse_args()\n",
    "else:\n",
    "    # if run as a notebook reduce the set of args\n",
    "    args = parser.parse_args([])\n",
    "    args.derivatives_dir='/data/derivatives'\n",
    "    args.rerun = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "derivatives_dir = args.derivatives_dir\n",
    "fmriprep_dir = path.join(derivatives_dir, 'fmriprep', 'fmriprep')\n",
    "first_level_dir = path.join(derivatives_dir, '1stlevel')\n",
    "second_level_dir = path.join(derivatives_dir,'2ndlevel')\n",
    "if args.working_dir is None:\n",
    "    working_dir = path.join(derivatives_dir, '2ndlevel_workingdir')\n",
    "else:\n",
    "    working_dir = path.join(args.working_dir, '2ndlevel_workingdir')\n",
    "makedirs(working_dir, exist_ok=True)\n",
    "    \n",
    "tasks = ['ANT', 'CCTHot', 'discountFix',\n",
    "         'DPX', 'motorSelectiveStop',\n",
    "         'stopSignal', 'stroop', \n",
    "         'surveyMedley', 'twoByTwo', 'WATT3']\n",
    "if args.tasks:\n",
    "    tasks = args.tasks\n",
    "regress_rt = args.ignore_rt\n",
    "model = 'model-rt' if regress_rt == True else 'model-nort'\n",
    "mask_threshold = args.mask_threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Group Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create mask over all tasks\n",
    "# create 95% brain mask\n",
    "mask_loc = path.join(second_level_dir, 'group_mask_thresh-%s.nii.gz' % str(mask_threshold))\n",
    "if path.exists(mask_loc) == False:\n",
    "    create_group_mask(mask_loc, fmriprep_dir, mask_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_img(mask_loc, title='Group Mask, Threshold: %s%%' % str(mask_threshold*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up functions with some default parameters\n",
    "get_group_maps = partial(get_group_maps, second_level_dir=second_level_dir,\n",
    "                        tasks=tasks, model=model)\n",
    "get_ICA_parcellation = partial(get_ICA_parcellation, second_level_dir=second_level_dir,\n",
    "                               mask_loc=mask_loc, working_dir=working_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data files\n",
    "file_type = 'zstat'\n",
    "map_files = get_map_files(map_prefix=file_type, \n",
    "                          first_level_dir=first_level_dir,\n",
    "                        tasks=tasks, model=model)\n",
    "contrast_names = list(map_files.keys())\n",
    "# reduce the number of files to make execution quicker for testing\n",
    "def random_sample(lst, n):\n",
    "    return [lst[i] for i in np.random.choice(range(len(lst)), n, replace=False)]\n",
    "metadata = get_metadata(map_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#iterative version\n",
    "concat_out = concat_map_files(map_files, file_type=individual_file_type,\n",
    "                                second_level_dir=second_level_dir, model=model,\n",
    "                                verbose=True)\n",
    "\"\"\"\n",
    "# concat files in parallel\n",
    "concat_map_files = partial(concat_map_files, file_type=file_type,\n",
    "                           second_level_dir=second_level_dir, model=model, verbose=False,\n",
    "                          rerun=args.rerun)\n",
    "\n",
    "list_dicts = [{k:map_files[k]} for k in map_files.keys()]\n",
    "concat_out = Parallel(n_jobs=args.n_procs)(delayed(concat_map_files)(task) for task in list_dicts)\n",
    "concat_out = flatten(concat_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the average  map for each contrast\n",
    "to_extract = concat_out\n",
    "group_map_files = get_mean_maps(to_extract, contrast_names, save=True, rerun=args.rerun)\n",
    "group_meta = get_metadata(group_map_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Group Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # #iterative version\n",
    "# # smooth_out = smooth_concat_files(concated_map_files, verbose=True)\n",
    "# # smooth files in parallel\n",
    "# smooth_concat_files = partial(smooth_concat_files, verbose=False, rerun=args.rerun)\n",
    "# smooth_out = Parallel(n_jobs=args.n_procs)(delayed(smooth_concat_files)([concat_file]) for concat_file in concat_out)\n",
    "# smooth_out = flatten(smooth_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # then tmap\n",
    "# contrast_tmap_parallel = partial(save_tmaps, mask_loc=mask_loc, working_dir=working_dir, \n",
    "#                                  permutations=args.num_perm, rerun=args.rerun)\n",
    "# tmap_out = Parallel(n_jobs=args.n_procs)(delayed(contrast_tmap_parallel)(filey) for filey in smooth_out)\n",
    "# tmap_raw, tmap_correct = zip(*tmap_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# % matplotlib inline\n",
    "# task_contrast_dirs = sorted(glob(path.join(second_level_dir, '*', 'model-rt', 'wf-contrast')))\n",
    "# for d in task_contrast_dirs:\n",
    "#     plot_2ndlevel_maps(d, lookup='*corrected*', threshold=.95) # *raw* for raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Searchlight RSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Beginning Searchlight Analysis')\n",
    "searchlight_dir = path.join(second_level_dir, 'Extracted_Data', 'searchlight')\n",
    "makedirs(path.join(searchlight_dir, 'Plots'), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.input_data.nifti_spheres_masker import _apply_mask_and_get_affinity\n",
    "from nilearn.input_data import NiftiSpheresMasker\n",
    "from scipy.spatial.distance import pdist\n",
    "\n",
    "def get_voxel_coords(mask_loc):\n",
    "    mask, mask_affine = masking._load_mask_img(mask_loc)\n",
    "    mask_coords = np.where(mask != 0)\n",
    "    process_mask_coords = image.resampling.coord_transform(\n",
    "            mask_coords[0], mask_coords[1],\n",
    "            mask_coords[2], mask_affine)\n",
    "    process_mask_coords = np.asarray(process_mask_coords).T\n",
    "    return process_mask_coords, mask\n",
    "\n",
    "def RSA(list_rows, X):\n",
    "    subset = X[:,list_rows]\n",
    "    return pdist(X[:,list_rows], metric='correlation')\n",
    "\n",
    "def searchlight_RSA(imgs, mask_loc, radius=10, n_jobs=4):\n",
    "    voxel_coords, mask = get_voxel_coords(mask_loc)\n",
    "    X, A = _apply_mask_and_get_affinity(voxel_coords, \n",
    "                                        imgs, \n",
    "                                        radius=radius, allow_overlap=True,\n",
    "                                        mask_img=mask_loc)\n",
    "    RDMs = Parallel(n_jobs=n_jobs)(\n",
    "                    delayed(RSA)(A.rows[list_i], X) for list_i in range(voxel_coords.shape[0]))\n",
    "    return RDMs, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_searchlight_file = path.join(searchlight_dir, 'groupcontrasts_searchlight_RDM.pkl')\n",
    "imgs = image.concat_imgs(group_map_files.values())\n",
    "if path.exists(group_searchlight_file) and not args.rerun:\n",
    "    RDMs, mask = pickle.load(open(group_searchlight_file, 'rb'))\n",
    "else:\n",
    "    RDMs, mask = searchlight_RSA(imgs, mask_loc)\n",
    "    pickle.dump([RDMs, mask], open(group_searchlight_file, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(3)\n",
    "vectorized_RDMs = np.vstack(RDMs)\n",
    "pca_RDMs = pca.fit_transform(vectorized_RDMs)\n",
    "scaled = minmax_scale(pca_RDMs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(pca.n_components):\n",
    "    RDM_3d = np.zeros(mask.shape)\n",
    "    values = np.zeros(np.sum(mask))\n",
    "    values[:len(RDMs)] = scaled[:,i]\n",
    "    RDM_3d[mask] = values\n",
    "    RDM_3d = image.new_img_like(mask_loc, RDM_3d)\n",
    "    # html for surface\n",
    "    view = plotting.view_img_on_surf(RDM_3d)\n",
    "    view.save_as_html(path.join(searchlight_dir, 'Plots', 'RSA_PCA%s_surface.html' % str(i+1)))\n",
    "    # pdf for volume\n",
    "    f = plt.figure(figsize=(30,10))\n",
    "    plotting.plot_stat_map(RDM_3d, figure=f, title='RSA PCA %s' % str(i+1))\n",
    "    f.savefig(path.join(searchlight_dir, 'Plots', 'RSA-PCA%s_volume.pdf' % str(i+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can also visualize the RDMs reflecting each of these first 3 components\n",
    "n_cols = 3\n",
    "n_rows = pca.n_components//n_cols\n",
    "index = group_meta.apply(lambda x: '_'.join(x), axis=1)\n",
    "for i, component in enumerate(pca.components_):\n",
    "    component_RDM = squareform(component)\n",
    "    component_RDM = pd.DataFrame(component_RDM, index=index, columns=index)\n",
    "    f = sns.clustermap(component_RDM)\n",
    "    f.savefig(path.join(searchlight_dir, 'Plots', 'RSA-PCA%s_clustermap.pdf' % str(i+1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parcellations, Atlases and RDM\n",
    "\n",
    "Projecting into a lower dimensional space allows the evaluation of whole-brain similarity analysis (clustering)\n",
    "\n",
    "RDMs can also be evaluated within parcellation regions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get parcellations to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Getting Parcellation')\n",
    "parcellation_dir = path.join(second_level_dir, 'parcellation')\n",
    "makedirs(parcellation_dir, exist_ok=True)\n",
    "\"\"\"\n",
    "# calculate ICA parcel\n",
    "n_comps = 20; ICA_prefix = 'contrast'\n",
    "ICA_path = path.join(parcellation_dir, '%s_canica%s.nii.gz' % (ICA_prefix, n_comps))\n",
    "if path.exists(ICA_path) and not args.rerun:\n",
    "    ICA_parcel = image.load_img(path.join(parcellation_dir, '%s_canica%s.nii.gz' % (ICA_prefix, n_comps)))\n",
    "else:\n",
    "    ICA_parcel = get_ICA_parcellation(map_files, n_comps=n_comps, file_name=ICA_prefix)\n",
    "\"\"\"\n",
    "# get literature parcels\n",
    "target_img = list(map_files.values())[0] # get image to resample atlases to\n",
    "harvard = get_established_parcellation(\"Harvard_Oxford\", target_img=target_img, parcellation_dir=parcellation_dir)\n",
    "#smith = get_established_parcellation(\"smith\", target_img=target_img, parcellation_dir=parcellation_dir)\n",
    "#glasser = get_established_parcellation(\"glasser\", target_img=target_img, parcellation_dir=parcellation_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# plotting.plot_prob_atlas(harvard_parcel)\n",
    "# # what is RegionExtractor?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use parcellation to create ROIs and calculate RDMs amongst contrasts within each ROI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parcel, parcel_labels, parcel_name, threshold = harvard\n",
    "roi_extraction_dir = second_level_dir\n",
    "extraction_dir = path.join(second_level_dir, 'Extracted_Data', 'parcel-%s' % parcel_name)\n",
    "makedirs(path.join(extraction_dir, 'Plots'), exist_ok=True)\n",
    "print('Using Parcellation: %s' % parcel_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(parcel.shape) == 4:\n",
    "    plotting.plot_prob_atlas(parcel, title=\"Parcellation\", cut_coords=[0, -41, 10])\n",
    "else:\n",
    "    plotting.plot_roi(parcel, title=\"Parcellation\", cut_coords=[0, -41, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate RDMs for each region for each group map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Calculating RDMs for each RDM based on group contrasts')\n",
    "group_extraction_file = path.join(extraction_dir, 'groupcontrasts_extraction.pkl')\n",
    "if path.exists(group_extraction_file) and not args.rerun:\n",
    "    group_roi_contrasts = pickle.load(open(group_extraction_file, 'rb'))\n",
    "else:\n",
    "    group_roi_contrasts = extract_roi_vals(group_map_files, parcel, extraction_dir, \n",
    "                                   threshold=threshold, metadata=group_meta, \n",
    "                                   labels=parcel_labels, rerun=args.rerun, \n",
    "                                   n_procs=args.n_procs, save=False)\n",
    "    tmp = odict()\n",
    "    for k,v in zip(parcel_labels, group_roi_contrasts):\n",
    "        tmp[k] = v\n",
    "    group_roi_contrasts = tmp\n",
    "    pickle.dump(group_roi_contrasts, open(group_extraction_file, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_RDMs = get_RDMs(group_roi_contrasts)\n",
    "keys = [k for k,v in group_RDMs.items() if v is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot random RDM\n",
    "label = np.random.choice(keys)\n",
    "index = parcel_labels.index(label)\n",
    "roi = get_ROI_from_parcel(parcel, index, threshold)\n",
    "RDM = group_RDMs[label]\n",
    "if RDM is not None:\n",
    "    RDM = pd.DataFrame(RDM, index=group_map_files.keys())\n",
    "    plot_RDM(RDM, roi, title=label, cluster=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RDM of RDMs\n",
    "\n",
    "Each ROI has an RDM reflecting its \"representation\" of cognitive faculties probed by these contrasts. We can look at the similarity of RDMs to get a sense of the similarity of the cognitive fingerprint of individual regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Group RDM of RDMs')\n",
    "def tril(square_mat):\n",
    "    return square_mat[np.tril_indices_from(square_mat, -1)]\n",
    "\n",
    "# similarity of RDMs\n",
    "vectorized_RDMs = np.vstack([tril(group_RDMs[k]) for k in keys if group_RDMs[k] is not None])\n",
    "vectorized_RDMs = pd.DataFrame(vectorized_RDMs, index=keys)\n",
    "RDM_of_RDMs = 1-vectorized_RDMs.T.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize RDM of RDMs\n",
    "clustermap = sns.clustermap(RDM_of_RDMs, figsize=[15,15])\n",
    "clustermap.savefig(path.join(extraction_dir, 'Plots', 'groupcontrasts_RDM_of_RDMs.pdf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA of RDMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('PCA Colored Map of RDMs')\n",
    "pca = PCA(3)\n",
    "pca_RDMs = pd.DataFrame(pca.fit_transform(vectorized_RDMs), index=vectorized_RDMs.index)\n",
    "scaled = minmax_scale(pca_RDMs)\n",
    "\n",
    "# find indices of skipped ROIs (for whatever reason) and set them to 0\n",
    "for i,label in enumerate(parcel_labels):\n",
    "    if label not in keys:\n",
    "        scaled = np.insert(scaled, i, [0]*pca.n_components, axis=0)\n",
    "        \n",
    "# we can then color the first 3 PCA components (RGB) and create color mixtures reflecting the RDM signature\n",
    "colors = np.array([[1,0,0], [0,1,0], [0,0,1]])\n",
    "def combined_colors(array, colors=colors):\n",
    "    return np.dot(colors, array)\n",
    "colored_pca = np.apply_along_axis(combined_colors, 1, scaled)\n",
    "\n",
    "# create colormaps\n",
    "all_color_list = colored_pca\n",
    "PC1_color_list = [[0,0,0]]+[colors[0]*i for i in scaled[:,0]]\n",
    "PC2_color_list = [[0,0,0]]+[colors[1]*i for i in scaled[:,1]]\n",
    "PC3_color_list = [[0,0,0]]+[colors[2]*i for i in scaled[:,2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare RDM after dimensional reduction\n",
    "i = np.random.randint(vectorized_RDMs.shape[0])\n",
    "f, axes = plt.subplots(1,2,figsize=(12,5))\n",
    "orig = vectorized_RDMs.iloc[i,:]\n",
    "reconstruction = pca.inverse_transform(pca_RDMs.iloc[i,:])\n",
    "corr = np.corrcoef(orig, reconstruction)[0,1]\n",
    "sns.heatmap(squareform(orig), ax=axes[0])\n",
    "sns.heatmap(squareform(reconstruction), ax=axes[1])\n",
    "axes[0].set_title(vectorized_RDMs.index[i])\n",
    "axes[1].set_title('PCA (%s) reconstruction, Corr: %0.2f' % (str(pca.n_components), corr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can also visualize the RDMs reflecting each of these first 3 components\n",
    "n_cols = 3\n",
    "n_rows = pca.n_components//n_cols\n",
    "index = group_meta.apply(lambda x: '_'.join(x), axis=1)\n",
    "for i, component in enumerate(pca.components_):\n",
    "    component_RDM = squareform(component)\n",
    "    component_RDM = pd.DataFrame(component_RDM, index=index, columns=index)\n",
    "    f = sns.clustermap(component_RDM)\n",
    "    f.savefig(path.join(extraction_dir, 'Plots', 'groupcontrasts_RSA-PCA%s_clustermap.pdf' % str(i+1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualize in the Volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = ListedColormap(all_color_list)\n",
    "f=plt.figure(figsize=(12,8))\n",
    "if len(parcel.shape) == 4:\n",
    "    plotting.plot_prob_atlas(parcel, cmap=cm, view_type='filled_contours', figure=f, \n",
    "                             title=\"RDM -> PCA -> colors (1: Red, 2: Green, 3: Blue)\")\n",
    "else:\n",
    "    plotting.plot_roi(parcel, cmap=cm, figure=f, \n",
    "                      title=\"RDM -> PCA -> colors (1: Red, 2: Green, 3: Blue)\")\n",
    "    f.savefig(path.join(extraction_dir, 'Plots', 'groupcontrasts_RSA-colored_volume.pdf' % str(i+1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualize on the Surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot on surface https://nilearn.github.io/plotting/index.html\n",
    "# fsaverage = datasets.fetch_surf_fsaverage(data_dir=parcellation_dir, mesh='fsaverage')\n",
    "# surf_mesh_l = fsaverage['infl_left']\n",
    "# surf_mesh_r = fsaverage['infl_right']\n",
    "# surf_projection = '/data/derivatives/2ndlevel/parcellation/glasser/lh.HCP-MMP1.annot'\n",
    "# surf_projection = nibabel.freesurfer.read_annot(surf_projection, orig_ids=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def convert_to_stat_map(parcel, values):\n",
    "#     data = parcel.get_data().copy()\n",
    "#     for i in range(1, np.max(data)+1):\n",
    "#         data[data==i] = values[i-1]\n",
    "#     return image.new_img_like(parcel, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot stat map on surface\n",
    "# n=pca.n_components\n",
    "# f, axes = plt.subplots(n,4, figsize=(24,6*n), subplot_kw={'projection': '3d'})\n",
    "# f.subplots_adjust(hspace=-.25)\n",
    "# f.subplots_adjust(wspace=-.2)\n",
    "# cmaps = ['Reds', 'Greens', 'Blues']\n",
    "# for i in range(n):\n",
    "#     cm = 'cold_hot'\n",
    "#     values = [row[i]*100 for row in scaled]\n",
    "#     to_plot = convert_to_stat_map(parcel,values)\n",
    "#     # left\n",
    "#     texture = nilearn.surface.vol_to_surf(to_plot, fsaverage.pial_left)\n",
    "#     _ = plotting.plot_surf_stat_map(surf_mesh_l, texture, hemi='left', axes=axes[i,0], figure=f, cmap=cm)\n",
    "#     _ = plotting.plot_surf_stat_map(surf_mesh_l, texture, hemi='left', view='medial', axes=axes[i,1], figure=f, cmap=cm)\n",
    "#     # right\n",
    "#     texture = nilearn.surface.vol_to_surf(to_plot, fsaverage.pial_right)\n",
    "#     _ = plotting.plot_surf_stat_map(surf_mesh_r, texture, hemi='right', view='medial', axes=axes[i,2], figure=f, cmap=cm)\n",
    "#     _ = plotting.plot_surf_stat_map(surf_mesh_r, texture, hemi='right', axes=axes[i,3], figure=f, cmap=cm)\n",
    "# f.savefig(path.join(extraction_dir, 'Plots', 'groupcontrasts_PC1-3.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot glasser annotation\n",
    "# f1=plt.figure(figsize=(12,8))\n",
    "# glassar_surface = plotting.plot_surf_stat_map(surf_mesh_l, surf_projection, figure=f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate RDMs for each region for each subject-contrast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# files = extract_roi_vals(to_extract, parcel, extraction_dir, \n",
    "#                  threshold=threshold, metadata=metadata, \n",
    "#                  labels=parcel_labels, rerun=args.rerun, \n",
    "#                  n_procs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply parcellations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# ********************************************************\n",
    "# Set up parcellation\n",
    "# ********************************************************\n",
    "\n",
    "#******************* Estimate parcellation from data ***********************\n",
    "print('Creating ICA based parcellation')\n",
    "\n",
    "\n",
    "# group map files by subject\n",
    "subject_ids = np.unique([f.split(os.sep)[-2].split('_')[0] for f in map_files])\n",
    "subject_map_files = []\n",
    "for s in subject_ids:\n",
    "    subject_map_files.append(image.concat_imgs([f for f in map_files if s in f]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ********************************************************\n",
    "# Reduce dimensionality of contrasts\n",
    "# ********************************************************\n",
    "def split_index(projections_df):\n",
    "    subj = [f.split('_')[0] for f in projections_df.index]\n",
    "    contrast = ['_'.join(f.split('_')[1:]) for f in projections_df.index]\n",
    "    projections_df.insert(0, 'subj', subj)\n",
    "    projections_df.insert(1, 'contrast', contrast)\n",
    "    \n",
    "    \n",
    "parcellation_files = [('smith70', smith_networks),\n",
    "                      ('canica20', \n",
    "                       join(output_dir, 'canica20_explicit_contrasts.nii.gz')),\n",
    "                      ('canica50', \n",
    "                       join(output_dir, 'canica50_explicit_contrasts.nii.gz')),\n",
    "                       ('canica70', \n",
    "                       join(output_dir, 'canica70_explicit_contrasts.nii.gz'))\n",
    "                       ]\n",
    "\n",
    "for parcellation_name, parcellation_file in parcellation_files:\n",
    "    projection_filey = join(output_dir, '%s_projection.json' % parcellation_name)\n",
    "    mask_file = join(output_dir, 'group_mask.nii.gz')\n",
    "    projections_df = create_projections_df(parcellation_file, mask_file, \n",
    "                                           data_dir, tasks, projection_filey)\n",
    "    \n",
    "    # create a subject x neural feature vector where each column is a component\n",
    "    # for one contrast\n",
    "    neural_feature_mat = create_neural_feature_mat(projections_df,\n",
    "                                                   filename=join(output_dir, \n",
    "                                                        '%s_neural_features.json'  \n",
    "                                                        % parcellation_name))\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "30px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
